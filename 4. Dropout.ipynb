{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "jqaejHHv9_h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvH8XsR0haq1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.io import show\n",
        "from bokeh.models import LinearAxis, Range1d\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "3AE0VMpZGfG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Download the CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "F2Emv9FNhexV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "num_classes = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "tnHXV_2nnZAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle= True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle= False)"
      ],
      "metadata": {
        "id": "HJFRE22skGT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building, Training, Testing"
      ],
      "metadata": {
        "id": "5CocmBGvGbbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = []\n",
        "test_accuracy = []\n",
        "\n",
        "# 10 here is number of experiments. With this setup, you will have the training of 10 epochs for 10 times.\n",
        "for i in range(10):\n",
        "\n",
        "  # model\n",
        "  class ConvNet(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(ConvNet, self).__init__()\n",
        "          self.layer1 = nn.Sequential(\n",
        "              nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "          self.layer2 = nn.Sequential(\n",
        "              nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "              nn.ReLU(),\n",
        "              nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "          self.drop_out = nn.Dropout(p = 0.5)   # ***************************************** You can change p value here *****************************************\n",
        "\n",
        "          self.fc1 = nn.Linear(8*8*64, 100)\n",
        "          self.act = nn.ReLU()\n",
        "          self.fc2 = nn.Linear(100, 10)\n",
        "\n",
        "      def forward(self, x):\n",
        "          out = self.layer1(x)\n",
        "          out = self.layer2(out)\n",
        "          out = out.reshape(out.size(0), -1)\n",
        "          out = self.drop_out(out)             # ************************************* Comment out this line to not use Dropout ***********************************\n",
        "          out = self.fc1(out)\n",
        "          out = self.act(out)\n",
        "          out = self.fc2(out)\n",
        "          return out\n",
        "\n",
        "\n",
        "  model = ConvNet()\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "\n",
        "  import torch\n",
        "  from torchsummary import summary\n",
        "  model.to('cuda')\n",
        "  input_data = torch.randn(1, 3, 32, 32).to('cuda')\n",
        "  summary(model, input_size=(3, 32, 32))\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Train the model\n",
        "  total_step = len(train_loader)\n",
        "  loss_list = []\n",
        "  acc_list = []\n",
        "\n",
        "  loss_plot = []\n",
        "  acc_plot = []\n",
        "  epoch_plot = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss_list.append(loss.item())\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          total = labels.size(0)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          correct = (predicted == labels).sum().item()\n",
        "          acc_list.append(correct / total)\n",
        "\n",
        "          epoch_plot.append(epoch+1)\n",
        "\n",
        "          if (i + 1) % 50 == 0:\n",
        "              print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                    .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
        "                            (correct / total) * 100))\n",
        "              loss_plot.append(loss.item())\n",
        "\n",
        "              acc_plot.append(correct / total)\n",
        "\n",
        "  train_accuracy.append((correct / total) * 100)\n",
        "\n",
        "  from bokeh.io import output_notebook, show\n",
        "\n",
        "\n",
        "  # Test the model\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      for images, labels in test_loader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Test Accuracy of the model on the 10000 test images: {} %'.format((correct / total) * 100))\n",
        "\n",
        "  test_accuracy.append((correct / total) * 100)\n"
      ],
      "metadata": {
        "id": "xfV_Gi7N_tj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_accuracy)"
      ],
      "metadata": {
        "id": "47-stJPuKrWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_accuracy)"
      ],
      "metadata": {
        "id": "J8uYfc7MwMlE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}